Notes

The main purpose of this project is to understand how to design a system leveraging microservices.

microservices are going to be running on a k8s cluster. 
That cluster's internal network is accessible to the outside world through the internet. 
Outside user accesses the internal services using the GATEWAY. 

Gateway communicates with the internal services the request received from client. 

To upload a file: gateway needs to have upload api

Auth service: Provides authorization to user to access fully the application endpoints. 

Basic Authentication: Userprovides username and password 
base64(username: Password), we check this in our mysql db. 
Gateway is the entry point to our system

JWT: JSON Web Token, Used for authentication and authorization
3 parts: 

Two json formatted strings and a signature
Base64 encoded. Seperated by a '.'

First part:
Header: Contains a kv pair 1. kind of signing algorithm (Uses SH256 symmetric signing algorithm), 2. type of token (in our case JWT)

Every api call uses the signing key (provides the access permissions)

Second Part:
Payload: Claims for user: pieces of information about the user. 
Eg. username, isadmin etc. 

3rd Part:
Verify Signature: 

1. Encoded header
2. Encoded Payload
3. Private Key 

All encoded using our signing algorithm.


Manifests:
We write the infrastructure code for our auth deployment
In python/src/auth :
We wrote the code for our auth service
We created a dockerfile to build the source code into a docker image
We then pushed the docker image to a repository on the internet

Now, within our manifests infrastructure code (auth-deploy.yaml)
We are pulling that image from the internet and deploying it to k8s
The image that we are pulling coutains our code. 

So all these files within the manifest directory
when applied, will interface with the k8s api which is the api for our k8s cluster
So these files will create our service and corresponding resources. 

To do this, all we need to do is kubectl apply -f ./ in the manifests directory 


Kubernetes:

K8s eliminates many of the manual operations in deploying and scaling containerized applications. 

For example, if we configure a service to have 4 pods, k8s will keep a track of all the pods up and running
And if any pods go down, then k8s will automatically scale the deployment so that the number of pods matches the 
configured amount. So there is no need to manually deploy individual pods when a pod crashes. 
K8s also makes manually scaling pods more streamlined. 

Say I have a service that load balances request to individual pods using round robin.
And that service is expeiencing more traffic than the pods to handle.
So we increase From 2 to 5 pods.
We can do this all using the command kubectl scale deployment --replicas=6 service

It will also autoconfigure the load balancer to handle the newly created pods. 

We can cluster together a bunch of containerized services and easily orchestrate


K8s object is a 'record of intent' - once you create the object, the K8s system will constantly work to ensure that object exits.
By creating an object, you are effectively telling the K8s system what you want your cluster's workload to look like;
this is your cluster's desired state. 


Required fields in .yaml files
apiVersion: Which version of the K8s api are we using to create this
Kind: What kind of object we are creating. 
metadata: Data that helps uniquely identify the object, including a name, string, UID, and optional namespace. 
spec: What state you desire for the object. Different for every K8s object type. 

Refer K8s api to check specs for different object types.
Deployment is a workload resource. 

spec for deployment:
apiVersion
kind 
metadata
spec:
    selector
        matchLabel
    replicas
    strategy:
        type: RollingUpdate
        rollingUpdate:
            maxSurge: 3
template:
    metadata:
        labels:
            app: auth 
    spec:
        containers:
            name: auth 
            image: jayjoshi1109/auth
            ports:
                containerPort: 5000
            envFrom:
                configMapRef:
                    name: auth-configMap
                secretRef:
                    name: auth-secret
                    
GRID FS: 

BSON Document: Binary JSON Document
The maximum BSON document size is 16 megabytes.

The maximum document size helps ensure that a single document cannot use excessive amoun tof RAM or, 
during transmission, excessive amount of bandwidth. To store documents larger than the maximum size, 
MongoDB provides, the GridFS API.

GridFS allows us to handle files bigger than 16 MB
by sharding the files. 

Instead of storing a file in a single document, GridFS divides the file into parts, or chunks, 
and stores each chunk as a separate document. By default, GridFS usees a default chunk size of 255kb.
that is, GridFS divides a file into chunks of 255kB with the exception of the last chunk. The last chunk 
is only as large as necessary.

Similarly, files that are no larger than the chunk size only have a final chunk, using only as much space as needed 
plus some additional metadata. 

Grid FS uses two collections to store files. One collection stores the file chunks, and the other stores file metadata. 
Collections in mongodb can be seen as tables. 

metadata: how to reassemble the chunks to reform the file. 


Rabbit MQ : (It is a queue)

When a video is uploaded to mongodb 
A message is added to queue
Letting downstream services know that there 
is a video to be processed
The video to mp3 converter will consume messages from q
After converting video to mp3 and storing it in the mongodb
the converter service will put a new message on the q
to be consumed by the notification service that the conversion job is done. 
The notification service then informs the client that the video is ready to be downloaded. 


Key Terms when considering microservice architecture
Synchronous and Asynchronous Interservice Communication
Synchronous: 
Client awaits for response from server. 
Client can't do anything until response from the server. 
Gateway service synchronously connects with auth service. 
Asynchronous:
Client does not need to await the response of the downstream service. 
This is a non-blocking request. This is achieved using a q.
Gateway service aysnchronouly connects with the converter service.
The gateway service uploads the video no mongodb and pushes a message to the q. 
The same happens between conversion service and notification service.


Strong Consistency vs Eventual Consistency 

Strong Consistency: 
Application Flow:
Video -> Gateway -> synchronous request -> Converter Service  -> 
After conversion converter provides id to download mp3 -> Gateway provides the id to the user for download
No need for q.

Eventual Consistency:
Our original Application Flow. 
Need for q. 





